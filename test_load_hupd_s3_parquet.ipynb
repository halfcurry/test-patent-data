{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df8b55f-63ef-457c-ba85-e92f672187c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:00:07.952416Z",
     "iopub.status.busy": "2025-06-14T14:00:07.951875Z",
     "iopub.status.idle": "2025-06-14T14:00:09.667383Z",
     "shell.execute_reply": "2025-06-14T14:00:09.666681Z",
     "shell.execute_reply.started": "2025-06-14T14:00:07.952384Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import s3fs # s3fs is typically pre-installed in SageMaker Data Science kernels\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0693d71-1482-4454-a5ac-50fb680707d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:11:27.125635Z",
     "iopub.status.busy": "2025-06-14T14:11:27.125322Z",
     "iopub.status.idle": "2025-06-14T14:11:27.129987Z",
     "shell.execute_reply": "2025-06-14T14:11:27.128761Z",
     "shell.execute_reply.started": "2025-06-14T14:11:27.125613Z"
    }
   },
   "outputs": [],
   "source": [
    "s3_parquet_path = \"s3://test-hupd-parquet-s3/2004.parquet/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcff5700-e1d4-4e46-a433-3dae5bc7ecd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:11:28.782814Z",
     "iopub.status.busy": "2025-06-14T14:11:28.782264Z",
     "iopub.status.idle": "2025-06-14T14:11:28.902078Z",
     "shell.execute_reply": "2025-06-14T14:11:28.901396Z",
     "shell.execute_reply.started": "2025-06-14T14:11:28.782790Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load Parquet data from S3: s3://test-hupd-parquet-s3/2004.parquet/\n",
      "\n",
      "--- Verifying S3 Access ---\n",
      "Successfully listed 416 items in s3://test-hupd-parquet-s3/2004.parquet/:\n",
      "- test-hupd-parquet-s3/2004.parquet/part.0.parquet\n",
      "- test-hupd-parquet-s3/2004.parquet/part.1.parquet\n",
      "- test-hupd-parquet-s3/2004.parquet/part.10.parquet\n",
      "- test-hupd-parquet-s3/2004.parquet/part.100.parquet\n",
      "- test-hupd-parquet-s3/2004.parquet/part.101.parquet\n"
     ]
    }
   ],
   "source": [
    "print(f\"Attempting to load Parquet data from S3: {s3_parquet_path}\")\n",
    "\n",
    "# --- Verify S3 Access and List Files (Optional but Recommended) ---\n",
    "print(\"\\n--- Verifying S3 Access ---\")\n",
    "try:\n",
    "    # s3fs will automatically use the IAM role attached to your SageMaker Studio instance\n",
    "    fs = s3fs.S3FileSystem()\n",
    "\n",
    "    # List contents of your S3 path to confirm access\n",
    "    s3_files = fs.ls(s3_parquet_path)\n",
    "    print(f\"Successfully listed {len(s3_files)} items in {s3_parquet_path}:\")\n",
    "    for f in s3_files[:5]: # Print first 5 files for brevity\n",
    "        print(f\"- {f}\")\n",
    "    if not s3_files:\n",
    "        print(\"Warning: No files found in the specified S3 path. Please double-check your path.\")\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: Could not list S3 files. This indicates a permission or path issue: {e}\")\n",
    "    print(\"Please ensure:\")\n",
    "    print(\"1. The S3 path is correct and points to a valid bucket/folder.\")\n",
    "    print(\"2. The IAM Role attached to your SageMaker Studio user has 's3:ListBucket' and 's3:GetObject' permissions for this bucket.\")\n",
    "    # If this fails, go back and re-check the IAM role permissions and role ARN for your user profile in the SageMaker Studio console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408d7bc6-44a2-4eef-be5e-b101cd92b42c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-14T14:11:38.165749Z",
     "iopub.status.busy": "2025-06-14T14:11:38.164999Z",
     "iopub.status.idle": "2025-06-14T14:11:58.970422Z",
     "shell.execute_reply": "2025-06-14T14:11:58.969749Z",
     "shell.execute_reply.started": "2025-06-14T14:11:38.165715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading with Dask DataFrame ---\n",
      "Dask DataFrame created successfully with 416 partitions.\n",
      "Dask DataFrame Schema:\n",
      "application_number      string[pyarrow]\n",
      "publication_number      string[pyarrow]\n",
      "title                   string[pyarrow]\n",
      "decision                string[pyarrow]\n",
      "date_produced           string[pyarrow]\n",
      "date_published          string[pyarrow]\n",
      "main_cpc_label          string[pyarrow]\n",
      "cpc_labels                       object\n",
      "main_ipcr_label         string[pyarrow]\n",
      "ipcr_labels                      object\n",
      "patent_number           string[pyarrow]\n",
      "filing_date             string[pyarrow]\n",
      "patent_issue_date       string[pyarrow]\n",
      "abandon_date            string[pyarrow]\n",
      "uspc_class              string[pyarrow]\n",
      "uspc_subclass           string[pyarrow]\n",
      "examiner_id             string[pyarrow]\n",
      "examiner_name_last      string[pyarrow]\n",
      "examiner_name_first     string[pyarrow]\n",
      "examiner_name_middle    string[pyarrow]\n",
      "inventor_list                    object\n",
      "abstract                string[pyarrow]\n",
      "summary                 string[pyarrow]\n",
      "full_description        string[pyarrow]\n",
      "dtype: object\n",
      "\n",
      "First 5 rows (this triggers a small computation):\n",
      "  application_number        publication_number  \\\n",
      "0           10986885  US20050148789A1-20050707   \n",
      "1           10496797  US20050070416A1-20050331   \n",
      "2           10953458  US20060070480A1-20060406   \n",
      "3           10735396  US20050066569A1-20050331   \n",
      "4           10502928  US20050085628A1-20050421   \n",
      "\n",
      "                                               title  decision date_produced  \\\n",
      "0            Process for preparing acrylate compound  ACCEPTED      20050623   \n",
      "1                         Flying tuck folding device  ACCEPTED      20050316   \n",
      "2  Bicycle brake control device with electrical o...  REJECTED      20060322   \n",
      "3                    Night fishman a rod reel holder  REJECTED      20050316   \n",
      "4  Production of hybridoma producing antihuman ce...  REJECTED      20050406   \n",
      "\n",
      "  date_published main_cpc_label cpc_labels main_ipcr_label ipcr_labels  ...  \\\n",
      "0       20050707                        []                          []  ...   \n",
      "1       20050331                        []                          []  ...   \n",
      "2       20060406                        []         F16C110   [F16C110]  ...   \n",
      "3       20050331                        []                          []  ...   \n",
      "4       20050421                        []                          []  ...   \n",
      "\n",
      "  uspc_class uspc_subclass examiner_id examiner_name_last examiner_name_first  \\\n",
      "0        549        420000     72597.0             TUCKER             ZACHARY   \n",
      "1        493        427000     71745.0             TAWFIK               SAMEH   \n",
      "2         74        502200     95143.0            JOHNSON             MATTHEW   \n",
      "3        043        017000     75849.0             BERONA            KIMBERLY   \n",
      "4        530        387100     61680.0          STANFIELD              CHERIE   \n",
      "\n",
      "  examiner_name_middle                                      inventor_list  \\\n",
      "0                       [{'inventor_city': 'Shinnanyo-shi', 'inventor_...   \n",
      "1                       [{'inventor_city': 'Speyer', 'inventor_country...   \n",
      "2                       [{'inventor_city': 'Kawachinagano-City', 'inve...   \n",
      "3                       [{'inventor_city': 'Theodosia', 'inventor_coun...   \n",
      "4                       [{'inventor_city': 'Aichi', 'inventor_country'...   \n",
      "\n",
      "                                            abstract  \\\n",
      "0  An acrylate compound of formula (4): is produc...   \n",
      "1  A folding apparatus utilizes a primary drive m...   \n",
      "2  A bicycle brake control device includes a brak...   \n",
      "3  Night Fishman, is a rod and reel holder, desig...   \n",
      "4  It is intended to provide antibodies, in parti...   \n",
      "\n",
      "                                             summary  \\\n",
      "0  <SOH> SUMMARY OF THE INVENTION  <EOH>In view o...   \n",
      "1  <SOH> SUMMARY OF THE INVENTION  <EOH>The objec...   \n",
      "2  <SOH> SUMMARY OF THE INVENTION  <EOH>One objec...   \n",
      "3                                                      \n",
      "4  <SOH> BRIEF DESCRIPTION OF THE DRAWINGS  <EOH>...   \n",
      "\n",
      "                                    full_description  \n",
      "0  BACKGROUND OF THE INVENTION (1) Field of the I...  \n",
      "1  FIELD OF THE INVENTION The present invention i...  \n",
      "2  BACKGROUND OF THE INVENTION 1. Field of the In...  \n",
      "3  1. This is a rod and reel holder, that is cons...  \n",
      "4  TECHNICAL FIELD The present invention relates ...  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "\n",
      "Counting total rows (this triggers the full data loading and processing):\n",
      "Total rows in dataset: 207710\n"
     ]
    }
   ],
   "source": [
    "# --- Load Data with Dask (Recommended for your ~4GB dataset) ---\n",
    "# Dask is best for datasets that might not fit into memory or are already partitioned.\n",
    "print(\"\\n--- Loading with Dask DataFrame ---\")\n",
    "try:\n",
    "    # Dask can directly read a directory containing multiple Parquet part files from S3\n",
    "    ddf = dd.read_parquet(s3_parquet_path)\n",
    "\n",
    "    print(f\"Dask DataFrame created successfully with {ddf.npartitions} partitions.\")\n",
    "    print(\"Dask DataFrame Schema:\")\n",
    "    print(ddf.dtypes)\n",
    "\n",
    "    print(\"\\nFirst 5 rows (this triggers a small computation):\")\n",
    "    print(ddf.head()) # .head() brings a small sample to local memory\n",
    "\n",
    "    # Example Dask computation: Get the total number of rows (triggers full data read)\n",
    "    print(\"\\nCounting total rows (this triggers the full data loading and processing):\")\n",
    "    # You can see the progress in the Dask dashboard link that pops up when you initialize Dask\n",
    "    total_rows = ddf.shape[0].compute()\n",
    "    print(f\"Total rows in dataset: {total_rows}\")\n",
    "\n",
    "    # Example: Calculate summary statistics for a numeric column (replace 'your_numeric_column' with an actual column name)\n",
    "    # print(\"\\nDescriptive statistics for a numeric column:\")\n",
    "    # if 'your_numeric_column' in ddf.columns:\n",
    "    #     stats = ddf['your_numeric_column'].describe().compute()\n",
    "    #     print(stats)\n",
    "    # else:\n",
    "    #     print(\"Skipping numeric column stats: 'your_numeric_column' not found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nERROR: Dask failed to load or process data: {e}\")\n",
    "    print(\"This could be due to:\")\n",
    "    print(\"- Incorrect S3 path or file format.\")\n",
    "    print(\"- Insufficient memory (even Dask needs some overhead; consider a larger instance if persistent crashes occur).\")\n",
    "    print(\"- Issues with the Parquet file integrity.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefcb9f8-96cb-454b-89b4-a316074644c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
